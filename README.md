# ProjetoAutomaçãoComIA
Processamento de Linguagem Natural (PLN) Local: Em vez de depender de APIs de nuvem, usei a biblioteca Ollama para rodar um modelo Llama3 localmente. Isso garante privacidade, segurança dos dados e um processamento super-rápido, sem custos por requisição.  Otimização e Performance: O script é otimizado com técnicas como cache (lru_cache), uso de expressões regulares pré-compiladas (re.compile) e multiprocessamento com concurrent.futures. Isso permite processar centenas de e-mails em questão de minutos.  Automação e Persistência: A integração com win32com.client permite o acesso direto ao Outlook. Os dados extraídos são validados e salvos de forma incremental em um banco de dados SQLite (SQLAlchemy), garantindo que apenas novas informações sejam adicionadas e que registros mais recentes possam atualizar os antigos.  As principais bibliotecas que tornaram isso possível são:  Ollama: Para a inferência da IA.  LangChain: Para orquestrar o processo de extração com prompts otimizados.  SQLAlchemy: Para a persistência de dados em um banco de dados robusto.  Pandas e Colorama: Para manipulação de dados e melhoria da experiência visual no console.  Este projeto não só automatiza uma tarefa manual e repetitiva, mas também demonstra como a IA local pode ser uma solução poderosa e eficiente para desafios de negócios.
